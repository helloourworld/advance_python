{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# jieba特性介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 支持三种分词模式：\n",
    "* 精确模式，试图将句子最精确地切开，适合文本分析；\n",
    "* 全模式，把句子中所有的可以成词的词语都扫描出来, 速度非常快，但是不能解决歧义；\n",
    "* 搜索引擎模式，在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词。\n",
    "* 支持繁体分词。\n",
    "* 支持自定义词典。\n",
    "* MIT 授权协议。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 分词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* jieba.cut 方法接受三个输入参数: 需要分词的字符串；cut_all 参数用来控制是否采用全模式；HMM 参数用来控制是否使用 HMM 模型。\n",
    "* jieba.cut_for_search 方法接受两个参数：需要分词的字符串；是否使用 HMM 模型。该方法适合用于搜索引擎构建倒排索引的分词，粒度比较细。\n",
    "* 待分词的字符串可以是 unicode 或 UTF-8 字符串、GBK 字符串。注意：不建议直接输入 GBK 字符串，可能无法预料地错误解码成 UTF-8。\n",
    "* jieba.cut 以及 jieba.cut_for_search 返回的结构都是一个可迭代的 generator，可以使用 for 循环来获得分词后得到的每一个词语(unicode)，或者用\n",
    "* **jieba.lcut 以及 jieba.lcut_for_search 直接返回 list。**\n",
    "* jieba.Tokenizer(dictionary=DEFAULT_DICT) 新建自定义分词器，可用于同时使用不同词典。jieba.dt 为默认分词器，所有全局分词相关函数都是该分词器的映射。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache c:\\users\\david\\appdata\\local\\temp\\jieba.cache\n",
      "Loading model cost 0.402 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Mode: 我/ 来到/ 北京/ 清华/ 清华大学/ 华大/ 大学\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "seg_list = jieba.cut(\"我来到北京清华大学\", cut_all=True)\n",
    "print(\"Full Mode: \" + \"/ \".join(seg_list))  # 全模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precise Mode: 我/来到/北京/清华大学\n"
     ]
    }
   ],
   "source": [
    "seg_list = jieba.cut(\"我来到北京清华大学\", cut_all = False)\n",
    "print(\"Precise Mode: \" + \"/\".join(seg_list))  #精确模式，默认状态下也是精确模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Mode: 他/来到/网易/杭研/大厦/。\n"
     ]
    }
   ],
   "source": [
    "seg_list = jieba.cut(\"他来到网易杭研大厦。\")\n",
    "print(\"Default Mode: \" + \"/\".join(seg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Mode: 小明/硕士/毕业/于/中国/科学/学院/科学院/中国科学院/计算/计算所/，/后/在/日本/京都/大学/日本京都大学/深造/。\n"
     ]
    }
   ],
   "source": [
    "seg_list = jieba.cut_for_search(\"小明硕士毕业于中国科学院计算所，后在日本京都大学深造。\")  #搜索引擎模式\n",
    "print(\"Search Mode: \" + \"/\".join(seg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. 添加自定义词典"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 载入词典\n",
    "\n",
    "* 开发者可以指定自己自定义的词典，以便包含 jieba 词库里没有的词。虽然 jieba 有新词识别能力，但是自行添加新词可以保证更高的正确率。\n",
    "* 用法： jieba.load_userdict(file_name) # file_name 为自定义词典的路径。\n",
    "* 词典格式和dict.txt一样，一个词占一行；每一行分三部分，一部分为词语，另一部分为词频（可省略），最后为词性（可省略），用空格隔开。\n",
    "* 词频可省略，使用计算出的能保证分出该词的词频。\n",
    "* 更改分词器的 tmp_dir 和 cache_file 属性，可指定缓存文件位置，用于受限的文件系统。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origin: 李小福/是/创新/办/主任/也/是/云/计算/方面/的/专家/。\n"
     ]
    }
   ],
   "source": [
    "seg_list = jieba.cut(\"李小福是创新办主任也是云计算方面的专家。\")\n",
    "print(\"Origin: \" + \"/\".join(seg_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调整词典\n",
    "\n",
    "* 使用 add_word(word, freq=None, tag=None) 和 del_word(word) 可在程序中动态修改词典。\n",
    "* 使用 suggest_freq(segment, tune=True) 可调节单个词语的词频，使其能（或不能）被分出来。\n",
    "* 注意：自动计算的词频在使用 HMM 新词发现功能时可能无效。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jieba.add_word(\"创新办\")\n",
    "jieba.add_word(\"云计算\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origin: 李小福/是/创新办/主任/也/是/云计算/方面/的/专家/。\n"
     ]
    }
   ],
   "source": [
    "seg_list = jieba.cut(\"李小福是创新办主任也是云计算方面的专家。\")\n",
    "print(\"Origin: \" + \"/\".join(seg_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "如果/放到/post/中将/出错/。\n"
     ]
    }
   ],
   "source": [
    "print(\"/\".join(jieba.cut(\"如果放到post中将出错。\", HMM = False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "494"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#利用调节词频使“中”，“将”都能被分出来\n",
    "jieba.suggest_freq((\"中\", \"将\"), tune = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "如果/放到/post/中/将/出错/。\n"
     ]
    }
   ],
   "source": [
    "print(\"/\".join(jieba.cut(\"如果放到post中将出错。\", HMM = False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 江州/市/长江大桥/参加/了/长江大桥/的/通车/仪式/。\n"
     ]
    }
   ],
   "source": [
    "Original = \"/\".join(jieba.cut(\"江州市长江大桥参加了长江大桥的通车仪式。\", HMM = False))\n",
    "print \"Original: \" + Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "江州/市长/江大桥/参加/了/长江大桥/的/通车/仪式/。\n"
     ]
    }
   ],
   "source": [
    "jieba.add_word(\"江大桥\", freq = 20000, tag = None)\n",
    "print \"/\".join(jieba.cut(\"江州市长江大桥参加了长江大桥的通车仪式。\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revise: 江州/市长/江大桥/参加/了/长江大桥/的/通车/仪式/。\n"
     ]
    }
   ],
   "source": [
    "print \"Revise: \" + \"/\".join(jieba.cut(\"江州市长江大桥参加了长江大桥的通车仪式。\", HMM = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. 词性标注"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* jieba.posseg.POSTokenizer(tokenizer=None) 新建自定义分词器，tokenizer 参数可指定内部使用的 jieba.Tokenizer 分词器。jieba.posseg.dt 为默认词性标注分词器。\n",
    "* 标注句子分词后每个词的词性，采用和 ictclas 兼容的标记法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我 r\n",
      "爱 v\n",
      "北京 ns\n",
      "天安门 ns\n",
      "。 x\n"
     ]
    }
   ],
   "source": [
    "import jieba.posseg as pseg\n",
    "words = pseg.cut(\"我爱北京天安门。\")\n",
    "for w in words:\n",
    "    print(\"%s %s\" %(w.word, w.flag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4. 关键词提取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于 TF-IDF 算法的关键词提取\n",
    "\n",
    "* import jieba.analyse\n",
    "* jieba.analyse.extract_tags(sentence, topK = 20, withWeight = False, allowPOS = ())\n",
    "* sentence:待提取的文本。\n",
    "* topK:返回几个 TF/IDF 权重最大的关键词，默认值为20。\n",
    "* withWeight:是否一并返回关键词权重值，默认值为False。\n",
    "* allowPOS:仅包括指定词性的词，默认值为空，即不进行筛选。\n",
    "* jieba.analyse.TFIDF(idf_path=None) 新建 TFIDF 实例，idf_path 为 IDF 频率文件。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> optparse模块OptionParser学习\n",
    "\n",
    "> **optparse是专门在命令行添加选项的一个模块。**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Option at 0xcfac1c8: -v/--vison>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from optparse import OptionParser\n",
    "MSG_USAGE = \"myprog[ -f ][-s ] arg1[,arg2..]\"\n",
    "optParser = OptionParser(MSG_USAGE)\n",
    "#以上，产生一个OptionParser的物件optParser。传入的值MSG_USAGE可被调用打印命令时显示出来。\n",
    "\n",
    "optParser.add_option(\"-f\",\"--file\",action = \"store\",type=\"string\",dest = \"fileName\")\n",
    "optParser.add_option(\"-v\",\"--vison\", action=\"store_false\", dest=\"verbose\",default='gggggg',\n",
    "                     help=\"make lots of noise [default]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file.txt\n",
      "False\n",
      "{'verbose': False, 'fileName': 'file.txt'}\n",
      "['good luck to you', 'arg2', 'arge']\n"
     ]
    }
   ],
   "source": [
    "#调用OptionParser.add_option()添加选项，add_option()参数说明：\n",
    "#action:存储方式，分为三种store, store_false, store_true\n",
    "#type:类型\n",
    "#dest:存储的变量\n",
    "#default:默认值\n",
    "#help:帮助信息\n",
    "\n",
    "fakeArgs = ['-f','file.txt','-v','good luck to you', 'arg2', 'arge']\n",
    "options, args = optParser.parse_args(fakeArgs)\n",
    "print options.fileName\n",
    "print options.verbose\n",
    "print options\n",
    "print args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: myprog[ -f ][-s ] arg1[,arg2..]\n",
      "\n",
      "Options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -f FILENAME, --file=FILENAME\n",
      "  -v, --vison           make lots of noise [default]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#调用OptionParser.parse_args()剖析并返回一个directory和一个list\n",
    "#parse_args()说明:\n",
    "#如果没有传入参数，parse_args会默认将sys.argv[1:]的值作为默认参数。这里我们将fakeArgs模拟输入的值。\n",
    "#从返回结果中可以看到，\n",
    "#options为是一个directory,它的内容fakeArgs为“参数/值 ”的键值对。\n",
    "#args 是一个list，它的内容是fakeargs除去options后，剩余的输入内容。\n",
    "#options.version和options.fileName都取到与options中的directory的值。\n",
    "\n",
    "print optParser.print_help()\n",
    "#输出帮助信息\n",
    "#optParser.print_help()说明：\n",
    "#1、最开始的的MSG_USAGE的值:在这个地方显示出来了。\n",
    "#2、自动添加了-h这个参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "退市 0.308235238937\n",
      "挂牌 0.298713335208\n",
      "三板 0.273846924336\n",
      "企业 0.181581599353\n",
      "常态 0.175024220843\n",
      "制度 0.16667492002\n",
      "2016 0.128545887128\n",
      "退出 0.124137365169\n",
      "市场化 0.116837921416\n",
      "摘牌 0.107622122085\n",
      "主动 0.102200631884\n",
      "出台 0.0985214310945\n",
      "一万家 0.0651017106597\n",
      "监管 0.0645245411703\n",
      "IPO 0.064272943564\n",
      "股转 0.064272943564\n",
      "化是 0.064272943564\n",
      "质量 0.0623125618245\n",
      "选择 0.0553848031875\n",
      "优胜劣汰 0.0539219174253\n"
     ]
    }
   ],
   "source": [
    "import jieba.analyse as anl\n",
    "fcontent = open(\"C_jieba_demo.txt\").read()\n",
    "seg = anl.extract_tags(fcontent, topK = 20, withWeight = True)\n",
    "for tag, weight in seg:\n",
    "    print \"%s %s\" %(tag, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿退市制度的推出是新三板完善制度建设的重要环节， 退市制度市场化和常态化是大势所趋。市场化，就是企业自主决定，主动退出。包括被并购整合，或因 IPO 摘牌，或企业认为的其它不适合继续挂牌的原因，而选择主动摘牌。常态化就是将没有持续经营能力或违法违规的企业清退出市场。 自从去年以来，新三板迎来了大扩容，由于挂牌门槛偏低， 部分企业虽然已经挂牌，但规范意识较差，不能适应后续的监管规则，这种严格化的信息披露要求和高压式的监管甚至成为了这些企业的负担，对于部分企业而言与其在新三板“站桩”耗费资源不如主动退出，因此我们预计未来新三板企业退市将实现市场化，这是解决挂牌企业质量参差不齐、保证新三板健康发展的有效手段。 而退市的常态化还需要政策层面的配合，在四季度股转系统已制定出台挂牌公司终止挂牌的实施细则，建立常态化退出机制，实现市场优胜劣汰，提高挂牌公司整体质量。 我们曾在 2016 年中期投资策略报告中，对退市制度的落地抱有较高的预期。事实上，退市制度已成为了 2016 下半年出台的最具有影响力的新政。监管部门选择在上市公司接近一万家规模的时候出台退市制度，有合理控制挂牌总体数量的意义在里面，时机恰到好处，因此受到了较为明显的效果。\n"
     ]
    }
   ],
   "source": [
    "print fcontent.decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 关键词提取所使用逆向文档频率（IDF）文本语料库可以切换成自定义语料库的路径。**\n",
    "\n",
    "* jieba.analyse.set_idf_path(file_name) #file_name为自定义语料库的路径\n",
    "* 如：jieba.analyse.set_idf_path(\"../extra_dict/idf.txt.big\")\n",
    "* .big文件一般是游戏中的文件，比较常见的用途是装载游戏的音乐、声音等文件。\n",
    "* \n",
    "* 关键词提取所使用停用词（Stop Words）文本语料库可以切换成自定义语料库的路径。\n",
    "* jieba.analyse.set_stop_words(file_name) #file_name为自定义语料库的路径。\n",
    "* 如：jieba.analyse.set_stop_words(\"../extra_dict/stop_words.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于 TextRank 算法的关键词提取\n",
    "\n",
    "* 基本思想:\n",
    "* 将待抽取关键词的文本进行分词；\n",
    "* 以固定窗口大小(默认为5，通过span属性调整)，词之间的共现关系，构建图；\n",
    "* 计算图中节点的PageRank，注意是无向带权图。\n",
    "* jieba.analyse.textrank(sentence, topK = 20, withWeight = False, allowPOS = ('ns', 'n', 'v', 'nv')) 注意默认过滤词性。\n",
    "* jieba.analyse.TextRank() 新建自定义TextRank实例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "吉林 1.0\n",
      "欧亚 0.996689335418\n",
      "置业 0.643436031309\n",
      "实现 0.589860669286\n",
      "收入 0.43677859948\n",
      "增资 0.409990053128\n",
      "子公司 0.356782959477\n",
      "城市 0.349713836674\n",
      "商业 0.34817220716\n",
      "业务 0.309223099262\n",
      "在建 0.307792916403\n",
      "营业 0.303577704932\n",
      "全资 0.303540981053\n",
      "综合体 0.295808691724\n",
      "注册资本 0.290005194641\n",
      "有限公司 0.280783079858\n",
      "零售 0.278836208612\n",
      "百货 0.278165762845\n",
      "开发 0.26934887793\n",
      "经营范围 0.264276217356\n"
     ]
    }
   ],
   "source": [
    "s = \"此外，公司拟对全资子公司吉林欧亚置业有限公司增资4.3亿元，增资后，吉林欧亚置业注册资本由7000万元增加到5亿元。吉林欧亚置业主要经营范围为房地产开发及百货零售等业务。目前在建吉林欧亚城市商业综合体项目。2013年，实现营业收入0万元，实现净利润-139.13万元。\"\n",
    "for x, w in jieba.analyse.textrank(s, topK = 20, withWeight = True):\n",
    "    print(\"%s %s\" % (x, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5 并行分词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 原理： 将目标文本按行分割后，把各行文本分配到多个python进程并行分词，然后归并结果，从而获得分词速度的可观提升。\n",
    "* 基于python自带的multiprocessing模块，目前暂不支持windows。\n",
    "* 用法：\n",
    "\n",
    "* jieba.enable_parallel(4) # 开启并行分词模式，参数为并行进程数\n",
    "* jieba.disable_parallel() # 关闭\n",
    "\n",
    "* 实验结果：在 4 核 3.4GHz Linux 机器上，对金庸全集进行精确分词，获得了 1MB/s 的速度，是单进程版的 3.3 倍。\n",
    "* **注意：并行分词仅支持默认分词器 jieba.dt 和 jieba.posseg.dt。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "——————————————————————————————————————\n"
     ]
    }
   ],
   "source": [
    "print \"——————————————————————————————————————\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6 Tokenize: 返回词语在原文的起止位置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 注意：输入参数只接受 unicode\n",
    "* 两种模式：默认模式、搜索模式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "永和 \t start at: 0 \t end at: 2\n",
      "服装 \t start at: 2 \t end at: 4\n",
      "饰品 \t start at: 4 \t end at: 6\n",
      "有限公司 \t start at: 6 \t end at: 10\n"
     ]
    }
   ],
   "source": [
    "result = jieba.tokenize(u\"永和服装饰品有限公司\")\n",
    "for tk in result:\n",
    "    print(\"%s \\t start at: %d \\t end at: %d\" %(tk[0], tk[1], tk[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "永和 \t start at: 0 \t end at: 2\n",
      "服装 \t start at: 2 \t end at: 4\n",
      "饰品 \t start at: 4 \t end at: 6\n",
      "有限 \t start at: 6 \t end at: 8\n",
      "公司 \t start at: 8 \t end at: 10\n",
      "有限公司 \t start at: 6 \t end at: 10\n"
     ]
    }
   ],
   "source": [
    "# ###搜索模式\n",
    "# 把句子中所有的可以成词的词语都扫描出来并确定位置。\n",
    "\n",
    "result = jieba.tokenize(u\"永和服装饰品有限公司\", mode = \"search\")\n",
    "for tk in result:\n",
    "    print(\"%s \\t start at: %d \\t end at: %d\" % (tk[0], tk[1], tk[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7 延迟加载机制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* jieba采用延迟加载，import jieba 和 jieba.Tokenizer() 不会立即触发词典的加载，一旦有必要才开始加载词典构建前缀字典。如果你想手工初始jieba，也可以手动初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "jieba.initialize() # 手动初始化，可选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 在 0.28 之前的版本是不能指定主词典的路径的，有了延迟加载机制后，你可以改变主词典的路径:\n",
    "# jieba.set_dictionary(\"data/dict.txt.big\")\n",
    "# 也可以下载你所需要的词典，然后覆盖jieba/dict.txt即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
